{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update: use NLTK to preprocess text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages and libraries\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import nltk as nk\n",
    "import re\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "\n",
    "from Semi_EM_NB import Semi_EM_MultinomialNB\n",
    "from time import time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load train and test data set with class labels \n",
    "train_Xy = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "test_Xy = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_noise(sentence):\n",
    "    result = ''\n",
    "    poster = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stopword_set = set(stopwords.words('english'))\n",
    "    wordlist = re.sub(r\"\\n|(\\\\(.*?){)|}|[!$%^&*#()_+|~\\-={}\\[\\]:\\\";'<>?,.\\/\\\\]|[0-9]|[@]\", ' ', sentence) # remove punctuation\n",
    "    wordlist = re.sub('\\s+', ' ', wordlist) # remove extra space\n",
    "    wordlist_normal = [poster.stem(word.lower()) for word in wordlist.split()] # restore word to its original form (stemming)\n",
    "    wordlist_normal = [lemmatizer.lemmatize(word, pos='v') for word in wordlist_normal] # restore word to its root form (lemmatization)\n",
    "    wordlist_clean = [word for word in wordlist_normal if word not in stopword_set] # remove stopwords\n",
    "    result = ' '.join(wordlist_clean)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocess train and test text data\n",
    "train_Xy.data_clean = map(remove_noise, train_Xy.data)\n",
    "test_Xy.data_clean = map(remove_noise, test_Xy.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 55213) (7532, 55213)\n"
     ]
    }
   ],
   "source": [
    "# Convert all text data into tf-idf vectors \n",
    "# vectorizer = TfidfVectorizer(stop_words='english', min_df=3, max_df=0.9)\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_vec = vectorizer.fit_transform(train_Xy.data_clean)\n",
    "test_vec = vectorizer.transform(test_Xy.data_clean)\n",
    "print train_vec.shape, test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1131, 55213) (10183, 55213)\n"
     ]
    }
   ],
   "source": [
    "# Divide train data set into labeled and unlabeled data sets\n",
    "n_train_data = train_vec.shape[0]\n",
    "split_ratio = 0.1 # labeled vs unlabeled\n",
    "X_l, X_u, y_l, y_u = train_test_split(train_vec, train_Xy.target, train_size=split_ratio, stratify=train_Xy.target)\n",
    "print X_l.shape, X_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(clf, data_X, data_y, unlabeled=None, n_folds=5):\n",
    "    print('=' * 80)\n",
    "    print(\"Validation: \")\n",
    "    print(clf)\n",
    "    kf = StratifiedKFold(n_splits=n_folds)\n",
    "    start_time = time()\n",
    "    train_accuracies= list() # training accuracy\n",
    "    fold_count = 1\n",
    "    original_clf = deepcopy(clf)\n",
    "    for train_ids, valid_ids in kf.split(data_X, data_y):\n",
    "        cv_clf = deepcopy(original_clf)\n",
    "        print(\"Fold # %d\" % fold_count)\n",
    "        fold_count += 1\n",
    "        train_X, train_y, valid_X, valid_y = data_X[train_ids], data_y[train_ids], data_X[valid_ids], data_y[valid_ids]\n",
    "        if unlabeled==None:\n",
    "            cv_clf.fit(train_X, train_y)\n",
    "        else:\n",
    "            cv_clf.fit(train_X, train_y, unlabeled)\n",
    "        pred = cv_clf.predict(valid_X)\n",
    "        train_accuracies.append(metrics.accuracy_score(valid_y, pred))\n",
    "    train_time = time() - start_time\n",
    "    print(\"Validation time: %0.3f seconds\" % train_time)\n",
    "    print(\"Average training accuracy: %0.3f\" % np.mean(np.array(train_accuracies)))\n",
    "    return train_accuracies, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Validation: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "Fold # 1\n",
      "Fold # 2\n",
      "Fold # 3\n",
      "Fold # 4\n",
      "Fold # 5\n",
      "Validation time: 0.231 seconds\n",
      "Average training accuracy: 0.567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.58874458874458879,\n",
       "  0.59999999999999998,\n",
       "  0.58515283842794763,\n",
       "  0.55111111111111111,\n",
       "  0.5092592592592593],\n",
       " 0.23097610473632812)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation for Naive Bayes classifier \n",
    "# using labeled data set only\n",
    "nb_clf = MultinomialNB(alpha=1e-2)\n",
    "cross_validation(nb_clf, X_l, y_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Validation: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "Fold # 1\n",
      "Initial expected log likelihood = -6199090.954\n",
      "\n",
      "EM iteration #1\n",
      "\tExpected log likelihood = -5409398.051\n",
      "EM iteration #2\n",
      "\tExpected log likelihood = -5404909.930\n",
      "EM iteration #3\n",
      "\tExpected log likelihood = -5404122.379\n",
      "EM iteration #4\n",
      "\tExpected log likelihood = -5403887.445\n",
      "EM iteration #5\n",
      "\tExpected log likelihood = -5403840.804\n",
      "EM iteration #6\n",
      "\tExpected log likelihood = -5403839.485\n",
      "EM iteration #7\n",
      "\tExpected log likelihood = -5403839.485\n",
      "Fold # 2\n",
      "Initial expected log likelihood = -6196076.322\n",
      "\n",
      "EM iteration #1\n",
      "\tExpected log likelihood = -5411278.872\n",
      "EM iteration #2\n",
      "\tExpected log likelihood = -5401494.662\n",
      "EM iteration #3\n",
      "\tExpected log likelihood = -5398884.683\n",
      "EM iteration #4\n",
      "\tExpected log likelihood = -5397134.440\n",
      "EM iteration #5\n",
      "\tExpected log likelihood = -5396168.538\n",
      "EM iteration #6\n",
      "\tExpected log likelihood = -5396168.538\n",
      "Fold # 3\n",
      "Initial expected log likelihood = -6203828.985\n",
      "\n",
      "EM iteration #1\n",
      "\tExpected log likelihood = -5412978.541\n",
      "EM iteration #2\n",
      "\tExpected log likelihood = -5408334.404\n",
      "EM iteration #3\n",
      "\tExpected log likelihood = -5407490.813\n",
      "EM iteration #4\n",
      "\tExpected log likelihood = -5407136.569\n",
      "EM iteration #5\n",
      "\tExpected log likelihood = -5407100.371\n",
      "EM iteration #6\n",
      "\tExpected log likelihood = -5407072.463\n",
      "EM iteration #7\n",
      "\tExpected log likelihood = -5407054.691\n",
      "EM iteration #8\n",
      "\tExpected log likelihood = -5407039.207\n",
      "EM iteration #9\n",
      "\tExpected log likelihood = -5407038.677\n",
      "EM iteration #10\n",
      "\tExpected log likelihood = -5407038.677\n",
      "Fold # 4\n",
      "Initial expected log likelihood = -6191493.498\n",
      "\n",
      "EM iteration #1\n",
      "\tExpected log likelihood = -5411090.150\n",
      "EM iteration #2\n",
      "\tExpected log likelihood = -5405764.613\n",
      "EM iteration #3\n",
      "\tExpected log likelihood = -5404904.386\n",
      "EM iteration #4\n",
      "\tExpected log likelihood = -5404875.648\n",
      "EM iteration #5\n",
      "\tExpected log likelihood = -5404722.284\n",
      "EM iteration #6\n",
      "\tExpected log likelihood = -5404719.245\n",
      "EM iteration #7\n",
      "\tExpected log likelihood = -5404719.245\n",
      "Fold # 5\n",
      "Initial expected log likelihood = -6185480.560\n",
      "\n",
      "EM iteration #1\n",
      "\tExpected log likelihood = -5411325.811\n",
      "EM iteration #2\n",
      "\tExpected log likelihood = -5407163.539\n",
      "EM iteration #3\n",
      "\tExpected log likelihood = -5405836.538\n",
      "EM iteration #4\n",
      "\tExpected log likelihood = -5405697.386\n",
      "EM iteration #5\n",
      "\tExpected log likelihood = -5405651.463\n",
      "EM iteration #6\n",
      "\tExpected log likelihood = -5405651.463\n",
      "Validation time: 659.371 seconds\n",
      "Average training accuracy: 0.599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.61038961038961037,\n",
       "  0.60434782608695647,\n",
       "  0.6026200873362445,\n",
       "  0.59111111111111114,\n",
       "  0.58796296296296291],\n",
       " 659.3714730739594)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation for semisupervised EM Naive Bayes classifier \n",
    "# using both labeled and unlabeled data set\n",
    "em_nb_clf = Semi_EM_MultinomialNB(alpha=1e-2) # semi supervised EM based Naive Bayes classifier\n",
    "cross_validation(em_nb_clf, X_l, y_l, X_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.50      0.32      0.39       319\n",
      "           comp.graphics       0.49      0.49      0.49       389\n",
      " comp.os.ms-windows.misc       0.56      0.33      0.41       394\n",
      "comp.sys.ibm.pc.hardware       0.46      0.66      0.54       392\n",
      "   comp.sys.mac.hardware       0.63      0.44      0.52       385\n",
      "          comp.windows.x       0.67      0.66      0.67       395\n",
      "            misc.forsale       0.76      0.53      0.62       390\n",
      "               rec.autos       0.68      0.63      0.65       396\n",
      "         rec.motorcycles       0.42      0.59      0.49       398\n",
      "      rec.sport.baseball       0.83      0.69      0.75       397\n",
      "        rec.sport.hockey       0.89      0.85      0.87       399\n",
      "               sci.crypt       0.39      0.80      0.52       396\n",
      "         sci.electronics       0.47      0.45      0.46       393\n",
      "                 sci.med       0.83      0.56      0.67       396\n",
      "               sci.space       0.61      0.62      0.62       394\n",
      "  soc.religion.christian       0.46      0.83      0.59       398\n",
      "      talk.politics.guns       0.54      0.45      0.49       364\n",
      "   talk.politics.mideast       0.54      0.76      0.63       376\n",
      "      talk.politics.misc       0.59      0.26      0.36       310\n",
      "      talk.religion.misc       0.29      0.03      0.05       251\n",
      "\n",
      "             avg / total       0.59      0.56      0.55      7532\n",
      "\n",
      "0.563197026022\n"
     ]
    }
   ],
   "source": [
    "# Evaluate original NB classifier using test data set\n",
    "nb_clf = MultinomialNB(alpha=1e-2).fit(X_l, y_l)\n",
    "pred = nb_clf.predict(test_vec)\n",
    "print(metrics.classification_report(test_Xy.target, pred, target_names=test_Xy.target_names))\n",
    "# pprint(metrics.confusion_matrix(test_Xy.target, pred))\n",
    "print(metrics.accuracy_score(test_Xy.target, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial expected log likelihood = -6116325.162\n",
      "\n",
      "EM iteration #1\n",
      "\tExpected log likelihood = -5407907.427\n",
      "EM iteration #2\n",
      "\tExpected log likelihood = -5403350.415\n",
      "EM iteration #3\n",
      "\tExpected log likelihood = -5402498.342\n",
      "EM iteration #4\n",
      "\tExpected log likelihood = -5402217.925\n",
      "EM iteration #5\n",
      "\tExpected log likelihood = -5402159.326\n",
      "EM iteration #6\n",
      "\tExpected log likelihood = -5402153.228\n",
      "EM iteration #7\n",
      "\tExpected log likelihood = -5402153.228\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.63      0.11      0.18       319\n",
      "           comp.graphics       0.58      0.56      0.57       389\n",
      " comp.os.ms-windows.misc       0.75      0.19      0.30       394\n",
      "comp.sys.ibm.pc.hardware       0.39      0.80      0.53       392\n",
      "   comp.sys.mac.hardware       0.75      0.37      0.49       385\n",
      "          comp.windows.x       0.75      0.76      0.75       395\n",
      "            misc.forsale       0.86      0.43      0.57       390\n",
      "               rec.autos       0.71      0.70      0.70       396\n",
      "         rec.motorcycles       0.80      0.60      0.68       398\n",
      "      rec.sport.baseball       0.93      0.79      0.86       397\n",
      "        rec.sport.hockey       0.95      0.88      0.92       399\n",
      "               sci.crypt       0.27      0.91      0.42       396\n",
      "         sci.electronics       0.60      0.43      0.50       393\n",
      "                 sci.med       0.91      0.60      0.73       396\n",
      "               sci.space       0.71      0.68      0.70       394\n",
      "  soc.religion.christian       0.39      0.91      0.54       398\n",
      "      talk.politics.guns       0.60      0.45      0.51       364\n",
      "   talk.politics.mideast       0.59      0.80      0.68       376\n",
      "      talk.politics.misc       0.76      0.18      0.29       310\n",
      "      talk.religion.misc       1.00      0.00      0.01       251\n",
      "\n",
      "             avg / total       0.69      0.58      0.56      7532\n",
      "\n",
      "0.57727031333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate semi-supervised EM NB classifier using test data set\n",
    "em_nb_clf = Semi_EM_MultinomialNB(alpha=1e-2).fit(X_l, y_l, X_u)\n",
    "pred = em_nb_clf.predict(test_vec)\n",
    "print(metrics.classification_report(test_Xy.target, pred, target_names=test_Xy.target_names))\n",
    "# pprint(metrics.confusion_matrix(test_Xy.target, pred))\n",
    "print(metrics.accuracy_score(test_Xy.target, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the most informative features \n",
    "import numpy as np\n",
    "def show_topK(classifier, vectorizer, categories, K=10):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        topK = np.argsort(classifier.coef_[i])[-K:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[topK])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: god believ religion think thi object atheist say wa moral\n",
      "comp.graphics: thi use ani polygon cview window file imag program graphic\n",
      "comp.os.ms-windows.misc: system download thi ani thank problem driver use file window\n",
      "comp.sys.ibm.pc.hardware: problem mous isa motherboard use thi drive card bu system\n",
      "comp.sys.mac.hardware: get mb ani quadra problem mous thank drive thi mac\n",
      "comp.windows.x: motif display mit list server widget thank thi use window\n",
      "misc.forsale: use trade condit cd price interest ship new offer sale\n",
      "rec.autos: ani anyon would buy thi gt dealer like wa car\n",
      "rec.motorcycles: front harley ride dod one know wa get motorcycl bike\n",
      "rec.sport.baseball: year cub brave score wa hi thi team win game\n",
      "rec.sport.hockey: main hawk wa hockey season play player nhl team game\n",
      "sci.crypt: bite govern protect use chip clipper secur thi encrypt key\n",
      "sci.electronics: smd one radio grind data thi would line wire use\n",
      "sci.med: jxp dsl diet food medic wa diseas one msg thi\n",
      "sci.space: satellit think sci launch wa would thi nasa rocket space\n",
      "soc.religion.christian: jesu hi bibl belief wa believ church thi christian god\n",
      "talk.politics.guns: bullet govern would nra lethal firearm use thi weapon gun\n",
      "talk.politics.mideast: turkey go peopl arab wa jew say isra israel armenian\n",
      "talk.politics.misc: drug forc peopl right wa libertarian homosexu job govern thi\n",
      "talk.religion.misc: wa god word point thi koresh theori object moral christian\n"
     ]
    }
   ],
   "source": [
    "show_topK(nb_clf, vectorizer, train_Xy.target_names, K=10) # keywords for each class by original NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: religion god think object atheism atheist islam say thi moral\n",
      "comp.graphics: packag window ani use thi thank program imag graphic file\n",
      "comp.os.ms-windows.misc: ftp thi thank font ax program use driver file window\n",
      "comp.sys.ibm.pc.hardware: mb disk thank problem ani thi scsi use card drive\n",
      "comp.sys.mac.hardware: monitor mb get card drive thank thi appl simm mac\n",
      "comp.windows.x: ani run program thank motif widget thi server use window\n",
      "misc.forsale: manual email price new condit includ sell ship offer sale\n",
      "rec.autos: one ani would buy like drive get thi wa car\n",
      "rec.motorcycles: go one helmet thi dod get motorcycl wa ride bike\n",
      "rec.sport.baseball: hit basebal win hi player pitch wa year team game\n",
      "rec.sport.hockey: thi win nhl season player hockey wa play team game\n",
      "sci.crypt: peopl wa clipper chip would govern use encrypt thi key\n",
      "sci.electronics: like grind would amp power circuit one get thi use\n",
      "sci.med: chastiti jxp diseas dsl pitt geb food gordon msg thi\n",
      "sci.space: shuttl one moon would launch thi wa orbit nasa space\n",
      "soc.religion.christian: peopl one believ hi say jesu wa thi christian god\n",
      "talk.politics.guns: fbi crime fire firearm peopl wa would weapon thi gun\n",
      "talk.politics.mideast: would say peopl jew arab thi isra armenian wa israel\n",
      "talk.politics.misc: clinton think drug say wa gay peopl thi tax homosexu\n",
      "talk.religion.misc: thi rosicrucian theori moral say wa object christian tyre koresh\n"
     ]
    }
   ],
   "source": [
    "show_topK(em_nb_clf, vectorizer, train_Xy.target_names, K=10) # keywords for each class by semisupervised EM NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
